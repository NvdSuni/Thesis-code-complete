{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIFM3io5cG1cAsFl7er5rd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NvdSuni/Thesis-code-complete/blob/main/XGboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXZ8QMxqkrk3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install optuna\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "import optuna\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import __version__ as sklearn_version\n",
        "import joblib\n",
        "\n",
        "\n",
        "import imblearn\n",
        "imblearn_version = imblearn.__version__\n",
        "\n",
        "print(f\"optuna: {optuna.__version__}\")\n",
        "print(f\"imbalanced-learn: {imblearn_version}\")\n",
        "print(f\"xgboost: {xgb.__version__}\")\n",
        "print(f\"numpy: {np.__version__}\")\n",
        "print(f\"matplotlib: {plt.matplotlib.__version__}\")\n",
        "print(f\"scikit-learn: {sklearn_version}\")\n",
        "print(f\"joblib: {joblib.__version__}\")\n"
      ],
      "metadata": {
        "id": "k8aTSRzAkv4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_combined = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/X_train_combined.npy\")\n",
        "X_val_combined = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/X_val_combined.npy\")\n",
        "y_train_combined = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/y_train_combined.npy\")\n",
        "y_val_combined = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/y_val_combined.npy\")"
      ],
      "metadata": {
        "id": "Dhzv71-Okxsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Untrained Model"
      ],
      "metadata": {
        "id": "TxvjmOcYky0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_classifier = xgb.XGBClassifier(objective='multi:softprob', num_class=7, eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "\n",
        "xgb_classifier.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "y_proba_xgb = xgb_classifier.predict_proba(X_val_combined)\n",
        "\n",
        "y_pred_xgb = np.argmax(y_proba_xgb, axis=1)\n",
        "\n",
        "roc_auc_xgb = roc_auc_score(y_val_combined, y_proba_xgb, multi_class='ovr')\n",
        "print(\"XGBoost ROC-AUC:\", roc_auc_xgb)\n",
        "\n",
        "report_xgb = classification_report(y_val_combined, y_pred_xgb)\n",
        "print(report_xgb)\n",
        "\n",
        "joblib.dump(xgb_classifier, '/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/Models/XGBoost/XGBoost.joblib')"
      ],
      "metadata": {
        "id": "_aVyZ8t1k0bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tuned Model"
      ],
      "metadata": {
        "id": "s5NeyG8Tk4Si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softmax',\n",
        "        'num_class': 7,\n",
        "        'random_state': 42,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'alpha': trial.suggest_float('alpha', 0.0, 1.0),\n",
        "        'lambda': trial.suggest_float('lambda', 0.0, 1.0),\n",
        "        'early_stopping_rounds': 15\n",
        "    }\n",
        "\n",
        "    xgb_classifier = xgb.XGBClassifier(**params)\n",
        "\n",
        "    eval_set = [(X_val_combined, y_val_combined)]\n",
        "\n",
        "    xgb_classifier.fit(X_train_combined, y_train_combined, eval_set = eval_set)\n",
        "\n",
        "    y_pred_proba = xgb_classifier.predict_proba(X_val_combined)\n",
        "    roc_auc = roc_auc_score(y_val_combined, y_pred_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "#Create the study object\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "best_params = study.best_params\n",
        "\n",
        "\n",
        "best_xgb_model = xgb.XGBClassifier(**best_params)\n",
        "best_xgb_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "\n",
        "y_pred_xgb_tuned = best_xgb_model.predict(X_val_combined)\n",
        "\n",
        "accuracy_xgb_tuned = accuracy_score(y_val_combined, y_pred_xgb_tuned)\n",
        "print(\"Tuned XGBoost Accuracy:\", accuracy_xgb_tuned)\n",
        "\n",
        "report_xgb_tuned = classification_report(y_val_combined, y_pred_xgb_tuned)\n",
        "print(report_xgb_tuned)\n",
        "\n",
        "joblib.dump(best_xgb_model, '/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/Models/XGBoost/XGBoost_tuned.joblib')"
      ],
      "metadata": {
        "id": "gJ0FL8f3k76R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class imbalance treated + Tuned"
      ],
      "metadata": {
        "id": "ySk9rscilJdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_combined, y_train_combined)"
      ],
      "metadata": {
        "id": "GtaLSTcomWkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softmax',\n",
        "        'num_class': 7,\n",
        "        'random_state': 42,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'alpha': trial.suggest_float('alpha', 0.0, 1.0),\n",
        "        'lambda': trial.suggest_float('lambda', 0.0, 1.0),\n",
        "        'early_stopping_rounds': 15\n",
        "    }\n",
        "\n",
        "    xgb_classifier = xgb.XGBClassifier(**params)\n",
        "\n",
        "    eval_set = [(X_val_combined, y_val_combined)]\n",
        "\n",
        "\n",
        "    xgb_classifier.fit(X_resampled, y_resampled, eval_set = eval_set)\n",
        "\n",
        "    y_pred_proba = xgb_classifier.predict_proba(X_val_combined)\n",
        "    roc_auc = roc_auc_score(y_val_combined, y_pred_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "#Create the study object\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "best_params = study.best_params\n",
        "\n",
        "\n",
        "best_xgb_model_smote = xgb.XGBClassifier(**best_params)\n",
        "best_xgb_model_smote.fit(X_resampled, y_resampled)\n",
        "\n",
        "\n",
        "y_pred_xgb_tuned_smote = best_xgb_model_smote.predict(X_val_combined)\n",
        "\n",
        "\n",
        "accuracy_xgb_tuned_smote = accuracy_score(y_val_combined, y_pred_xgb_tuned)\n",
        "print(\"Tuned XGBoost Accuracy:\", accuracy_xgb_tuned_smote)\n",
        "\n",
        "report_xgb_tuned_smote = classification_report(y_val_combined, y_pred_xgb_tuned)\n",
        "print(report_xgb_tuned_smote)\n",
        "joblib.dump(best_xgb_model_smote, '/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/Models/XGBoost/XGBoost_tuned_smote.joblib')"
      ],
      "metadata": {
        "id": "N_ujuJRYmX4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#X-ray Specific"
      ],
      "metadata": {
        "id": "wBM8-Jnymcha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_Xray = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/X_train_Xray_reduced.npy\")\n",
        "X_val_Xray = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/X_val_Xray_reduced.npy\")\n",
        "y_train_Xray = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/train_labels_complete_Xray.npy\")\n",
        "y_val_Xray = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/val_labels_complete_Xray.npy\")"
      ],
      "metadata": {
        "id": "6j3A0xFzmeSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_1d = np.argmax(y_train_Xray, axis=1)\n",
        "y_val_1d = np.argmax(y_val_Xray, axis=1)"
      ],
      "metadata": {
        "id": "SLvoZXg5mhWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the training data\n",
        "X_train_shuffled_Xray, y_train_shuffled_Xray = shuffle(X_train_Xray, y_train_1d, random_state=42)\n",
        "X_val_shuffled_Xray, y_val_shuffled_Xray = shuffle(X_val_Xray, y_val_1d, random_state=42)"
      ],
      "metadata": {
        "id": "1UIIUWbOmjdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost: Xray Untuned"
      ],
      "metadata": {
        "id": "cD9If7rFml96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_classifier_Xray = xgb.XGBClassifier(objective='multi:softmax', num_class=5, random_state=42, eval_metric='mlogloss')\n",
        "\n",
        "\n",
        "xgb_classifier_Xray.fit(X_train_shuffled_Xray, y_train_shuffled_Xray, eval_set=[(X_val_shuffled_Xray, y_val_shuffled_Xray)], verbose=True)\n",
        "\n",
        "y_pred_xgb = xgb_classifier_Xray.predict(X_val_shuffled_Xray)\n",
        "\n",
        "accuracy_xgb_Xray = accuracy_score(y_val_shuffled_Xray, y_pred_xgb)\n",
        "print(\"XGBoost Accuracy:\", accuracy_xgb_Xray)\n",
        "\n",
        "\n",
        "roc_auc_Xray = roc_auc_score(y_val_shuffled_Xray, xgb_classifier_Xray.predict_proba(X_val_shuffled_Xray), multi_class='ovr')\n",
        "print(\"XGBoost ROC-AUC:\", roc_auc_Xray)\n",
        "\n",
        "report_xgb_Xray = classification_report(y_val_shuffled_Xray, y_pred_xgb)\n",
        "print(report_xgb_Xray)\n",
        "\n",
        "joblib.dump(xgb_classifier_Xray, '/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/Models/XGBoost/XGBoost_Xray.joblib')"
      ],
      "metadata": {
        "id": "yi-cxM5dmnVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Xray specific: Tuned model"
      ],
      "metadata": {
        "id": "rm-1kEXCmrHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softmax',\n",
        "        'num_class': 5,\n",
        "        'random_state': 42,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'alpha': trial.suggest_float('alpha', 0.0, 1.0),\n",
        "        'lambda': trial.suggest_float('lambda', 0.0, 1.0),\n",
        "        'early_stopping_rounds': 15\n",
        "    }\n",
        "\n",
        "    xgb_classifier_Xray_tuned = xgb.XGBClassifier(**params)\n",
        "\n",
        "    xgb_classifier_Xray_tuned.fit(X_train_shuffled_Xray, y_train_shuffled_Xray, eval_set=[(X_val_shuffled_Xray, y_val_shuffled_Xray)], verbose=True)\n",
        "\n",
        "    y_pred_proba = xgb_classifier_Xray_tuned.predict_proba(X_val_shuffled_Xray)\n",
        "    roc_auc = roc_auc_score(y_val_shuffled_Xray, y_pred_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "\n",
        "best_xgb_model_Xray = xgb.XGBClassifier(**best_params)\n",
        "best_xgb_model_Xray.fit(X_train_shuffled_Xray, y_train_shuffled_Xray, eval_metric='mlogloss')\n",
        "\n",
        "y_pred_proba_tuned_Xray = best_xgb_model_Xray.predict_proba(X_val_shuffled_Xray)\n",
        "\n",
        "y_pred_tuned_Xray = np.argmax(y_pred_proba_tuned_Xray, axis=1)\n",
        "\n",
        "\n",
        "roc_auc_tuned_Xray = roc_auc_score(y_val_shuffled_Xray, y_pred_proba_tuned_Xray, multi_class='ovr', average='macro')\n",
        "print(\"Tuned XGBoost ROC-AUC:\", roc_auc_tuned_Xray)\n",
        "\n",
        "report_xgb_tuned_Xray = classification_report(y_val_shuffled_Xray, y_pred_tuned_Xray)\n",
        "print(report_xgb_tuned_Xray)\n",
        "\n",
        "joblib.dump(xgb_classifier_Xray, '/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/Models/XGBoost/XGBoost_tuned_Xray.joblib')"
      ],
      "metadata": {
        "id": "zPAUB1nAmsir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Xray specific: Class imbalance treated and Tuned\n"
      ],
      "metadata": {
        "id": "kSlVqNQJmx9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_shuffled_Xray, y_train_shuffled_Xray)"
      ],
      "metadata": {
        "id": "9rqNzPs1mzwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softmax',\n",
        "        'num_class': 7,\n",
        "        'random_state': 42,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'alpha': trial.suggest_float('alpha', 0.0, 1.0),\n",
        "        'lambda': trial.suggest_float('lambda', 0.0, 1.0),\n",
        "        'early_stopping_rounds': 15\n",
        "    }\n",
        "\n",
        "    xgb_classifier_Xray_tuned_smote = xgb.XGBClassifier(**params)\n",
        "\n",
        "    evals = [(X_val_shuffled_Xray, y_val_shuffled_Xray)]\n",
        "    xgb_classifier_Xray_tuned_smote.fit(\n",
        "        X_train_smote,\n",
        "        y_train_smote,\n",
        "        eval_set=evals,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    y_proba = xgb_classifier_Xray_tuned_smote.predict_proba(X_val_shuffled_Xray)\n",
        "    roc_auc = roc_auc_score(y_val_shuffled_Xray, y_proba, multi_class='ovr')\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "\n",
        "best_xgb_classifier_Xray_tuned_smote = xgb.XGBClassifier(**best_params)\n",
        "best_xgb_classifier_Xray_tuned_smote.fit(X_train_smote, y_train_smote, eval_metric='mlogloss', eval_set=[(X_val_shuffled_Xray, y_val_shuffled_Xray)], verbose=False)\n",
        "\n",
        "\n",
        "y_pred_xgb = best_xgb_classifier_Xray_tuned_smote.predict(X_val_shuffled_Xray)\n",
        "accuracy_xgb_Xray_tuned_smote = accuracy_score(y_val_shuffled_Xray, y_pred_xgb)\n",
        "print(\"XGBoost Accuracy:\", accuracy_xgb_Xray_tuned_smote)\n",
        "\n",
        "\n",
        "roc_auc_final = roc_auc_score(y_val_shuffled_Xray, best_xgb_classifier_Xray_tuned_smote.predict_proba(X_val_shuffled_Xray), multi_class='ovr')\n",
        "print(\"XGBoost ROC-AUC:\", roc_auc_final)\n",
        "\n",
        "\n",
        "report_xgb_final_Xray_tuned_smote = classification_report(y_val_shuffled_Xray, y_pred_xgb)\n",
        "print(report_xgb_final_Xray_tuned_smote)\n",
        "\n",
        "joblib.dump(best_xgb_classifier_Xray_tuned_smote, '/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/Models/XGBoost/XGBoost_tuned_smote_Xray.joblib')"
      ],
      "metadata": {
        "id": "rj0W-Mgum1hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MRI Specific"
      ],
      "metadata": {
        "id": "C3x47upcm58C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_MRNet = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/X_train_MRNet_reduced.npy\")\n",
        "X_val_MRNet = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/X_val_MRNet_reduced.npy\")\n",
        "y_train_MRNet = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/y_train_MRNet.npy\")\n",
        "y_val_MRNet = np.load(\"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/y_val_MRNet.npy\")"
      ],
      "metadata": {
        "id": "zfFrYjY8m6-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_classifier_MRI = xgb.XGBClassifier(objective='binary:logistic', random_state=42, eval_metric='logloss')\n",
        "\n",
        "\n",
        "xgb_classifier_MRI.fit(X_train_MRNet, y_train_MRNet, eval_set=[(X_val_MRNet, y_val_MRNet)], verbose=True)\n",
        "\n",
        "y_pred_xgb_MRNet = xgb_classifier_MRI.predict(X_val_MRNet)\n",
        "\n",
        "accuracy_xgb_MRNet = accuracy_score(y_val_MRNet, y_pred_xgb_MRNet)\n",
        "print(\"XGBoost Accuracy:\", accuracy_xgb_MRNet)\n",
        "\n",
        "roc_auc = roc_auc_score(y_val_MRNet, xgb_classifier_MRI.predict_proba(X_val_MRNet)[:, 1])\n",
        "print(\"XGBoost ROC-AUC:\", roc_auc)\n",
        "\n",
        "report_xgb_MRNet = classification_report(y_val_MRNet, y_pred_xgb_MRNet)\n",
        "print(report_xgb_MRNet)\n",
        "joblib.dump(xgb_classifier_MRI, \"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/Models/XGBoost/XGBoost_MRI.joblib\")"
      ],
      "metadata": {
        "id": "FcBtD4YKm8cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MRI Specific: Tuned model"
      ],
      "metadata": {
        "id": "M0iiFgHonFFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'random_state': 42,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'alpha': trial.suggest_float('alpha', 0.0, 1.0),\n",
        "        'lambda': trial.suggest_float('lambda', 0.0, 1.0),\n",
        "        'early_stopping_rounds': 15\n",
        "    }\n",
        "\n",
        "    xgb_classifier_tuned_MRI = xgb.XGBClassifier(**params, eval_metric='logloss')\n",
        "\n",
        "    xgb_classifier_tuned_MRI.fit(X_train_MRNet, y_train_MRNet, eval_set=[(X_val_MRNet, y_val_MRNet)], verbose=True\n",
        "    )\n",
        "\n",
        "    y_pred_proba = xgb_classifier_tuned_MRI.predict_proba(X_val_MRNet)[:, 1]\n",
        "    roc_auc = roc_auc_score(y_val_MRNet, y_pred_proba)\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "best_params = study.best_params\n",
        "\n",
        "\n",
        "best_xgb_model_MRNet = xgb.XGBClassifier(**best_params, early_stopping_rounds=15, eval_metric='logloss')\n",
        "best_xgb_model_MRNet.fit(X_train_MRNet, y_train_MRNet, eval_set=[(X_val_MRNet, y_val_MRNet)], verbose=True)\n",
        "\n",
        "\n",
        "y_pred_proba_tuned_MRNet = best_xgb_model_MRNet.predict_proba(X_val_MRNet)[:, 1]\n",
        "\n",
        "\n",
        "y_pred_tuned_MRNet = np.round(y_pred_proba_tuned_MRNet)\n",
        "\n",
        "roc_auc_tuned_MRNet = roc_auc_score(y_val_MRNet, y_pred_proba_tuned_MRNet)\n",
        "print(\"Tuned XGBoost ROC-AUC:\", roc_auc_tuned_MRNet)\n",
        "\n",
        "report_xgb_tuned_MRNet = classification_report(y_val_MRNet, y_pred_tuned_MRNet)\n",
        "print(report_xgb_tuned_MRNet)\n",
        "\n",
        "joblib.dump(best_xgb_model_MRNet, \"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/Models/XGBoost/XGBoost_tuned_MRI.joblib\")"
      ],
      "metadata": {
        "id": "wzaVV2penJLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MRI Specific: Class imbalance treated and Tuned"
      ],
      "metadata": {
        "id": "_XwMi3a4nRDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote_MRNet, y_train_smote_MRNet = smote.fit_resample(X_train_MRNet, y_train_MRNet)\n",
        "print(X_train_smote_MRNet.shape, y_train_smote_MRNet.shape)"
      ],
      "metadata": {
        "id": "0b_xR2shnSVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'random_state': 42,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'alpha': trial.suggest_float('alpha', 0.0, 1.0),\n",
        "        'lambda': trial.suggest_float('lambda', 0.0, 1.0),\n",
        "        'early_stopping_rounds': 15,\n",
        "    }\n",
        "\n",
        "    xgb_classifier_tuned_smote_MRI = xgb.XGBClassifier(**params)\n",
        "\n",
        "    xgb_classifier_tuned_smote_MRI.fit(X_train_smote_MRNet, y_train_smote_MRNet, eval_set=[(X_val_MRNet, y_val_MRNet)], verbose=True)\n",
        "\n",
        "    y_pred_proba = xgb_classifier_tuned_smote_MRI.predict_proba(X_val_MRNet)[:, 1]\n",
        "    roc_auc = roc_auc_score(y_val_MRNet, y_pred_proba)\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "\n",
        "best_params = study.best_params\n",
        "\n",
        "best_xgb_model_MRNet_smote = xgb.XGBClassifier(**best_params, early_stopping_rounds=15, eval_metric='logloss')\n",
        "\n",
        "best_xgb_model_MRNet_smote.fit(X_train_smote_MRNet, y_train_smote_MRNet, eval_set=[(X_val_MRNet, y_val_MRNet)], verbose=True)\n",
        "\n",
        "\n",
        "y_pred_proba_tuned_MRNet_smote = best_xgb_model_MRNet_smote.predict_proba(X_val_MRNet)[:, 1]\n",
        "\n",
        "\n",
        "y_pred_tuned_MRNet_smote = np.round(y_pred_proba_tuned_MRNet_smote)\n",
        "\n",
        "\n",
        "roc_auc_tuned_MRNet = roc_auc_score(y_val_MRNet, y_pred_proba_tuned_MRNet_smote)\n",
        "print(\"Tuned XGBoost ROC-AUC:\", roc_auc_tuned_MRNet)\n",
        "\n",
        "report_xgb_tuned_MRNet_smote = classification_report(y_val_MRNet, y_pred_tuned_MRNet_smote)\n",
        "print(report_xgb_tuned_MRNet_smote)\n",
        "\n",
        "joblib.dump(best_xgb_model_MRNet_smote, \"/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/Models/XGBoost/XGBoost_tuned_smote_MRI.joblib\")"
      ],
      "metadata": {
        "id": "1ICBHTkJnTHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}