{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+F6ZTVSLly7WZi8VjNPe0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NvdSuni/Thesis-code-complete/blob/main/X_ray_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and loading data"
      ],
      "metadata": {
        "id": "IPKoMVF-cUZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28-zS2X5cOBo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print versions\n",
        "print(f\"numpy: {np.__version__}\")\n",
        "print(f\"PIL (Pillow): {Image.__version__}\")\n",
        "print(f\"tensorflow: {tf.__version__}\")"
      ],
      "metadata": {
        "id": "xnp2H1PucRDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vit-keras\n",
        "!pip install timm"
      ],
      "metadata": {
        "id": "6HKpNNc0cSLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "xv6aJ4KNeOoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_paths(data_dir):\n",
        "    image_paths = []\n",
        "    for class_dir in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_dir)\n",
        "        for image_file in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_file)\n",
        "            image_paths.append(image_path)\n",
        "    return image_paths\n",
        "\n",
        "train_image_dir = '/content/drive/My Drive/Tilburg University/Thesis/Master Thesis/KneeXrayData/ClsKLData/kneeKL299/train'\n",
        "val_image_dir = '/content/drive/My Drive/Master Thesis/KneeXrayData/ClsKLData/kneeKL299/val'\n",
        "test_image_dir = '/content/drive/My Drive/Master Thesis/KneeXrayData/ClsKLData/kneeKL299/test'\n",
        "\n",
        "train_image_paths = get_image_paths(train_image_dir)\n",
        "val_image_paths = get_image_paths(val_image_dir)\n",
        "test_image_paths = get_image_paths(test_image_dir)\n",
        "\n",
        "num_classes = 5\n",
        "\n",
        "def create_labels(image_paths):\n",
        "    labels = [int(image_path.split(\"/\")[-2]) for image_path in image_paths]\n",
        "    labels = np.array(labels)\n",
        "    labels = to_categorical(labels, num_classes)\n",
        "    return labels\n",
        "\n",
        "train_labels = create_labels(train_image_paths)\n",
        "val_labels = create_labels(val_image_paths)\n",
        "test_labels = create_labels(test_image_paths)\n",
        "\n",
        "\n",
        "image_size = (224, 224)\n",
        "\n",
        "#Manual preprocessing for the training set\n",
        "preprocessed_train_data = []\n",
        "for image_path in train_image_paths:\n",
        "    with Image.open(image_path) as image:\n",
        "        image = image.resize(image_size, Image.LANCZOS)\n",
        "        preprocessed_train_data.append(np.array(image) / 255.0)\n",
        "\n",
        "#Manual preprocessing for the validation set\n",
        "preprocessed_val_data = []\n",
        "for image_path in val_image_paths:\n",
        "    with Image.open(image_path) as image:\n",
        "        image = image.resize(image_size, Image.LANCZOS)\n",
        "        preprocessed_val_data.append(np.array(image) / 255.0)\n",
        "\n",
        "#Manual preprocessing for the test set\n",
        "preprocessed_test_data = []\n",
        "for image_path in test_image_paths:\n",
        "    with Image.open(image_path) as image:\n",
        "        image = image.resize(image_size, Image.LANCZOS)\n",
        "        preprocessed_test_data.append(np.array(image) / 255.0)\n",
        "\n",
        "#Save preprocessed data\n",
        "np.save('/content/drive/My Drive/Master Thesis/KneeXrayData/preprocessed_train_data.npy', np.array(preprocessed_train_data))\n",
        "np.save('/content/drive/My Drive/Master Thesis/KneeXrayData/preprocessed_val_data.npy', np.array(preprocessed_val_data))\n",
        "np.save('/content/drive/My Drive/Master Thesis/KneeXrayData/preprocessed_test_data.npy', np.array(preprocessed_test_data))\n",
        "np.save('/content/drive/My Drive/Master Thesis/KneeXrayData/preprocessed_train_labels.npy', np.array(train_labels))\n",
        "np.save('/content/drive/My Drive/Master Thesis/KneeXrayData/preprocessed_val_labels.npy', np.array(val_labels))\n",
        "np.save('/content/drive/My Drive/Master Thesis/KneeXrayData/preprocessed_test_labels.npy', np.array(test_labels))\n"
      ],
      "metadata": {
        "id": "3rymZUcqcXjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_dir = '/content/drive/My Drive/Tilburg University/Thesis/Master Thesis/KneeXrayData/ClsKLData/kneeKL224/train'\n",
        "val_image_dir = '/content/drive/My Drive/Tilburg University/Thesis/Master Thesis/KneeXrayData/ClsKLData/kneeKL224/val'\n",
        "test_image_dir = '/content/drive/My Drive/Tilburg University/Thesis/Master Thesis/KneeXrayData/ClsKLData/kneeKL224/test'\n",
        "\n",
        "train_image_paths = get_image_paths(train_image_dir)\n",
        "val_image_paths = get_image_paths(val_image_dir)\n",
        "test_image_paths = get_image_paths(test_image_dir)\n",
        "\n",
        "num_classes = 5\n",
        "\n",
        "def create_labels(image_paths):\n",
        "    labels = [int(image_path.split(\"/\")[-2]) for image_path in image_paths]\n",
        "    labels = np.array(labels)\n",
        "    labels = to_categorical(labels, num_classes)\n",
        "    return labels\n",
        "\n",
        "train_labels_224 = create_labels(train_image_paths)\n",
        "val_labels_224 = create_labels(val_image_paths)\n",
        "test_labels_224 = create_labels(test_image_paths)\n",
        "\n",
        "image_size = (224, 224)\n",
        "\n",
        "#Manual preprocessing for the training set\n",
        "preprocessed_train_data_224 = []\n",
        "for image_path in train_image_paths:\n",
        "    with Image.open(image_path) as image:\n",
        "        image = image.resize(image_size, Image.LANCZOS)\n",
        "        preprocessed_train_data_224.append(np.array(image) / 255.0)\n",
        "\n",
        "#Manual preprocessing for the validation set\n",
        "preprocessed_val_data_224 = []\n",
        "for image_path in val_image_paths:\n",
        "    with Image.open(image_path) as image:\n",
        "        image = image.resize(image_size, Image.LANCZOS)\n",
        "        preprocessed_val_data_224.append(np.array(image) / 255.0)\n",
        "\n",
        "#Manual preprocessing for the test set\n",
        "preprocessed_test_data_224 = []\n",
        "for image_path in test_image_paths:\n",
        "    with Image.open(image_path) as image:\n",
        "        image = image.resize(image_size, Image.LANCZOS)\n",
        "        preprocessed_test_data_224.append(np.array(image) / 255.0)\n",
        "\n",
        "#Save preprocessed data\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_train_data_224.npy', np.array(preprocessed_train_data_224))\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_val_data_224.npy', np.array(preprocessed_val_data_224))\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_test_data_224.npy', np.array(preprocessed_test_data_224))\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_train_labels_224.npy', np.array(train_labels_224))\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_val_labels_224.npy', np.array(val_labels_224))\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_test_labels_224.npy', np.array(test_labels_224))"
      ],
      "metadata": {
        "id": "rn2dxPaKczCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_data = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_train_data.npy')\n",
        "preprocessed_val_data = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_val_data.npy')\n",
        "preprocessed_test_data = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_test_data.npy')\n",
        "train_labels = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_train_labels.npy')\n",
        "val_labels = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_val_labels.npy')\n",
        "test_labels = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_test_labels.npy')"
      ],
      "metadata": {
        "id": "FKEf_KBbc7zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_data_224 = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_train_data_224.npy')\n",
        "preprocessed_val_data_224 = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_val_data_224.npy')\n",
        "preprocessed_test_data_224 = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_test_data_224.npy')\n",
        "train_labels_224 = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_train_labels_224.npy')\n",
        "val_labels_224 = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_val_labels_224.npy')\n",
        "test_labels_224 = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_test_labels_224.npy')"
      ],
      "metadata": {
        "id": "a4A8HzEqdAgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine preprocessed training data\n",
        "preprocessed_train_data_combined = np.concatenate((preprocessed_train_data, preprocessed_train_data_224), axis=0)\n",
        "preprocessed_val_data_combined = np.concatenate((preprocessed_val_data, preprocessed_val_data_224), axis=0)\n",
        "preprocessed_test_data_combined = np.concatenate((preprocessed_test_data, preprocessed_test_data_224), axis=0)\n",
        "\n",
        "#Combine corresponding training labels\n",
        "train_labels_combined = np.concatenate((train_labels, train_labels_224), axis=0)\n",
        "val_labels_combined = np.concatenate((val_labels, val_labels_224), axis=0)\n",
        "test_labels_combined = np.concatenate((test_labels, test_labels_224), axis=0)\n"
      ],
      "metadata": {
        "id": "zbZIfiIVdBjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_data = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_train_data_complete.npy')\n",
        "preprocessed_val_data = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_val_data_complete.npy')\n",
        "preprocessed_test_data = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_test_data_complete.npy')\n",
        "train_labels = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/train_labels_complete_Xray.npy')\n",
        "val_labels = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/val_labels_complete_Xray.npy')\n",
        "test_labels = np.load('/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/test_labels_complete_Xray.npy')"
      ],
      "metadata": {
        "id": "8yebpqeWdDQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#Calculate the mean and standard deviation from the training data\n",
        "mean = np.mean(preprocessed_train_data, axis=(0, 1, 2))\n",
        "std = np.std(preprocessed_train_data, axis=(0, 1, 2))\n",
        "\n",
        "#Standardize the data\n",
        "preprocessed_train_data_standardized = (preprocessed_train_data - mean) / std\n",
        "preprocessed_val_data_standardized = (preprocessed_val_data - mean) / std\n",
        "preprocessed_test_data_standardized = (preprocessed_test_data - mean) / std\n"
      ],
      "metadata": {
        "id": "7FHPe_h3dKSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_train_data_complete.npy', np.array(preprocessed_train_data_standardized))\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_val_data_complete.npy', np.array(preprocessed_val_data_standardized))\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/preprocessed_test_data_complete.npy', np.array(preprocessed_test_data_standardized))"
      ],
      "metadata": {
        "id": "Coh1hyykdO4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature extraction"
      ],
      "metadata": {
        "id": "KkWMUheZeQyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "\n",
        "#Model\n",
        "basic_model_xray = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1), name = \"COV1\"),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu', name = \"COV2\"),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax', name = \"output_layer\")\n",
        "])\n",
        "\n",
        "basic_model_xray.compile(optimizer='adam',\n",
        "                   loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "basic_model_xray.summary()\n",
        "#Training\n",
        "history = basic_model_xray.fit(\n",
        "    preprocessed_train_data,\n",
        "    train_labels,\n",
        "    epochs = 20,\n",
        "    validation_data=(preprocessed_val_data, val_labels),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "evaluation_results = basic_model_xray.evaluate(preprocessed_test_data, test_labels)\n",
        "print(\"Evaluation results on the test dataset:\", evaluation_results)"
      ],
      "metadata": {
        "id": "3X0SUhEGdQqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract features from the \"COV2\" layer\n",
        "cnn_feature_extractor_xray = Model(inputs=basic_model_xray.input, outputs=basic_model_xray.get_layer(\"COV2\").output, name=\"cnn_feature_extractor_xray2.0\")\n",
        "\n",
        "#Save the CNN feature extractor model\n",
        "cnn_feature_extractor_xray.save('/content/drive/My Drive/Tilburg University/Master Thesis/KneeXrayData/cnn_feature_extractor_xray2.0')\n"
      ],
      "metadata": {
        "id": "7xcai449dSCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_data1 = preprocessed_train_data[:5785]\n",
        "preprocessed_train_data2 = preprocessed_train_data[5785:]"
      ],
      "metadata": {
        "id": "qbBpIYvYdSHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "cnn_features_X_train_Xray1 = []\n",
        "\n",
        "for i in range(0, len(preprocessed_train_data1), batch_size):\n",
        "    batch_data = preprocessed_train_data1[i:i + batch_size]\n",
        "    features = cnn_feature_extractor_xray.predict(batch_data)\n",
        "    cnn_features_X_train_Xray1.append(features)\n",
        "\n",
        "#Concatenate the results\n",
        "cnn_features_X_train_Xray1 = np.concatenate(cnn_features_X_train_Xray1, axis=0)\n",
        "\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/cnn_features_X_train_Xray1.npy', cnn_features_X_train_Xray1)"
      ],
      "metadata": {
        "id": "XkjGuu8GdaaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_features_X_train_Xray2 = []\n",
        "\n",
        "for i in range(0, len(preprocessed_train_data2), batch_size):\n",
        "    batch_data = preprocessed_train_data2[i:i + batch_size]\n",
        "    features = cnn_feature_extractor_xray.predict(batch_data)\n",
        "    cnn_features_X_train_Xray2.append(features)\n",
        "\n",
        "#Concatenate the results\n",
        "cnn_features_X_train_Xray2 = np.concatenate(cnn_features_X_train_Xray2, axis=0)\n",
        "\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/cnn_features_X_train_Xray2.npy', cnn_features_X_train_Xray2)"
      ],
      "metadata": {
        "id": "wShDFDSydiGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_features_X_val_Xray = []\n",
        "\n",
        "for i in range(0, len(preprocessed_val_data), batch_size):\n",
        "    batch_data = preprocessed_val_data[i:i + batch_size]\n",
        "    features = cnn_feature_extractor_xray.predict(batch_data)\n",
        "    cnn_features_X_val_Xray.append(features)\n",
        "\n",
        "#Concatenate the results\n",
        "cnn_features_X_val_Xray = np.concatenate(cnn_features_X_val_Xray, axis=0)\n",
        "\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/cnn_features_X_val_Xray.npy', cnn_features_X_val_Xray)"
      ],
      "metadata": {
        "id": "nKrKGLHId0kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_features_X_test_Xray = []\n",
        "\n",
        "for i in range(0, len(preprocessed_test_data), batch_size):\n",
        "    batch_data = preprocessed_test_data[i:i + batch_size]\n",
        "    features = cnn_feature_extractor_xray.predict(batch_data)\n",
        "    cnn_features_X_test_Xray.append(features)\n",
        "\n",
        "#Concatenate the results\n",
        "cnn_features_X_test_Xray = np.concatenate(cnn_features_X_test_Xray, axis=0)\n",
        "\n",
        "np.save('/content/drive/My Drive/Tilburg University/Master Thesis/Combined data/cnn_features_X_test_Xray.npy', cnn_features_X_test_Xray)"
      ],
      "metadata": {
        "id": "zu6iTzRQd6Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualisation"
      ],
      "metadata": {
        "id": "VXRHlMIMeU6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count occurrences for each grade\n",
        "grade_counts = np.sum(train_labels, axis=0)\n",
        "\n",
        "# Bar plot\n",
        "grades = [f\"Grade {i}\" for i in range(len(grade_counts))]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(grades, grade_counts, color=\"#b6d7a8\", label=\"Grade Counts\")\n",
        "plt.ylabel('Number of samples')\n",
        "plt.xlabel(\"Grades\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y7tEOW3GeDR5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}